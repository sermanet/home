**Research Scientist** in Deep Learning, Computer Vision, Robotics, Self-Supervised Learning @ **Google Brain**<br>
[[LinkedIn]](https://www.linkedin.com/in/sermanet/) [[Scholar]](https://scholar.google.com/citations?user=0nPi5YYAAAAJ) [[YouTube]](https://www.youtube.com/user/nyulagr) [[Twitter]](https://twitter.com/psermanet) [[Email: first dot last at gmail]]()

| Projects |  |
| ------------- | ------------- |
| <img src='docs/figs/kuka_pouring.mov.gif' width='270'>  | **Time-Contrastive Networks (TCN)**<br>[[Project Page]](https://sermanet.github.io/imitate/) [[ Paper ]](https://arxiv.org/abs/1704.06888) [[BibTex]](http://dblp.uni-trier.de/rec/bibtex/journals/corr/SermanetLHL17) [[ Video ]](https://www.youtube.com/watch?v=b1UTUQpxPSY) [[ Dataset ]](https://sites.google.com/site/brainrobotdata/home/multiview-pouring) [[Code]]()  |
| <img src='docs/figs/kuka_dishrack.mov.gif' width='270'>  |  **Unsupervised Perceptual Rewards**<br>[[Project Page]](https://sermanet.github.io/rewards/) [[ Paper ]](https://arxiv.org/abs/1612.06699) [[BibTex]](https://github.com/sermanet/home/blob/master/docs/bib/Sermanet2017Rewards.bib) [[ Video ]](https://youtu.be/7f7sdLMCItg) [[ Dataset ]](https://sites.google.com/site/brainrobotdata/home/pouring-dataset) |
| <img src='docs/figs/pose_all.mov.gif' width='270'>  |  **Self-Supervised Imitation Learning**<br>[[Project Page]](https://sermanet.github.io/imitation/) |
| <img src='docs/figs/googlenet_diagram.png' width='270'>  | **Visual Attention**<br>[[Paper]](https://arxiv.org/abs/1412.7054) [[BibTex]](https://github.com/sermanet/home/blob/master/docs/bib/Sermanet2015Attention.bib)|
| <img src='docs/figs/googlenet_diagram.png' width='270'>  | **Inception / GoogLeNet**<br>[[Code]](https://github.com/tensorflow/models/tree/master/research/inception) [[Paper]](https://www.cv-foundation.org/openaccess/content_cvpr_2015/papers/Szegedy_Going_Deeper_With_2015_CVPR_paper.pdf) [[BibTex]](https://github.com/sermanet/home/blob/master/docs/bib/Szegedy2015Inception.bib) [[ImageNet Challenge]](http://www.image-net.org/challenges/LSVRC/2014/results)|
| <img src='docs/figs/cat_dogs.png' width='270'>  |  **Dogs vs. Cats Kaggle challenge**<br>[[Leaderboard]](https://www.kaggle.com/c/dogs-vs-cats/leaderboard)  |
| <img src='docs/figs/ms_nofine_clean.png' width='270'>  | **OverFeat**<br>[[Code]](https://github.com/sermanet/OverFeat) [[Paper]](https://arxiv.org/abs/1312.6229) [[BibTex]](https://github.com/sermanet/home/blob/master/docs/bib/Sermanet2014OverFeat.bib) [[Slides]](http://www.image-net.org/challenges/LSVRC/2013/slides/overfeat_ilsvrc2013.pdf) [[ImageNet Challenge]](http://www.image-net.org/challenges/LSVRC/2013/results.php) [[Press]](https://machinelearning.apple.com/2017/11/16/face-detection.html)|
| <img src='docs/figs/ms_nofine_clean.png' width='270'>  | **Pedestrian Detection**<br>[[Video]](https://www.youtube.com/watch?v=uKU2pzpGUlM) [[Paper]](https://www.cv-foundation.org/openaccess/content_cvpr_2013/html/Sermanet_Pedestrian_Detection_with_2013_CVPR_paper.html) [[BibTex]](https://github.com/sermanet/home/blob/master/docs/bib/Sermanet2013Pedestrian.bib)|
| <img src='docs/figs/.png' width='270'>  | **Convolutional Neural Networks Applied to House Numbers Digit Classification**<br>[[Paper]](https://arxiv.org/pdf/1204.3968.pdf) [[BibTex]](
https://github.com/sermanet/home/blob/master/docs/bib/Sermanet2012Convolutional.bib)|
| <img src='docs/figs/traffic_signs.png' width='270'><br><img src='docs/figs/convnet_skip_connections.png' width='270'>  | **Traffic Sign Recognition**<br>[[Paper]](http://yann.lecun.com/exdb/publis/pdf/sermanet-ijcnn-11.pdf) [[BibTex]](https://github.com/sermanet/home/blob/master/docs/bib/Sermanet2011Traffic.bib) |
| <img src='docs/figs/unsupervised_filters.png' width='270'>  | **Unsupervised Convolutional Feature Hierarchies**<br>[[Paper]](http://papers.nips.cc/paper/4133-learning-convolutional-feature-hierarchies-for-visual-recognition.pdf) [[BibTex]](https://github.com/sermanet/home/blob/master/docs/bib/Kavukcuoglu2010Unsupervised.bib)|
| <img src='docs/figs/faces.png' width='270'>  | **EBLearn**<br>[[Code]](http://eblearn.sourceforge.net/) [[Paper]](http://yann.lecun.com/exdb/publis/pdf/sermanet-ictai-09.pdf) [[BibTex]](https://github.com/sermanet/home/blob/master/docs/bib/Sermanet2009EBLearn.bib) |
| <img src='docs/figs/.png' width='270'>  | **Teaching NYU Robotics class**<br> |
| <img src='docs/figs/.png' width='270'>  | **LAGR**<br> |
| <img src='docs/figs/.png' width='270'>  | **Learning Long-Range Vision for Autonomous Off-Road Driving**<br>[[Paper]](http://www.cs.nyu.edu/~sermanet/lagr/papers/hadsell-jfr-09_wiley.pdf) [[BibTex]](https://github.com/sermanet/home/blob/master/docs/bib/Hadsell2009Learning.bib) |
| <img src='docs/figs/.png' width='270'>  | **Collision-Free Off-Road Robot Navigation**<br>[[Paper]](https://cs.nyu.edu/~sermanet/lagr/papers/sermanet-jfr-09_wiley.pdf) [[BibTex]](https://github.com/sermanet/home/blob/master/docs/bib/Sermanet2009Multirange.bib) |
| <img src='docs/figs/maneuvers.png' width='270'>  | **Learning Maneuver Dictionaries for Ground Robot Planning**<br>[[Paper]](http://yann.lecun.com/exdb/publis/pdf/sermanet-isr-08.pdf) [[BibTex]](https://github.com/sermanet/home/blob/master/docs/bib/Sermanet2008Learning.bib) |
| <img src='docs/figs/.png' width='270'>  | **Mapping and Planning under Uncertainty in Mobile Robots with Long-Range Perception**<br>[[Paper]](http://yann.lecun.com/exdb/publis/pdf/sermanet-iros-08.pdf) [[BibTex]](https://github.com/sermanet/home/blob/master/docs/bib/Sermanet2008Mapping.bib) |
| <img src='docs/figs/long_range.png' width='270'>  | **Deep Belief Net Learning in a Long-Range Vision System**<br>[[Paper]](https://cs.nyu.edu/~naz/docs/iros08.pdf) [[BibTex]](https://github.com/sermanet/home/blob/master/docs/bib/Hadsell2008Deep.bib) |
| <img src='docs/figs/online_learning.png' width='270'>  | **Online Learning for Offroad Robots**<br>[[Paper]](http://yann.lecun.com/exdb/publis/pdf/hadsell-rss-07.pdf) [[BibTex]](https://github.com/sermanet/home/blob/master/docs/bib/Hadsell2007Online.bib) |
| <img src='docs/figs/.png' width='270'>  | **EUROBOT**<br> |
